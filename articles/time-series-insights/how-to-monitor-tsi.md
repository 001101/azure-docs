---
title: 'Monitoring Time Series Insights | Microsoft Docs'
description: Monitor Time Series Insights for availability, performance, and operation.
author: deepakpalled
ms.author: lyhughes
manager: diviso
ms.workload: big-data
ms.service: time-series-insights
services: time-series-insights
ms.topic: conceptual
ms.date: 12/10/2020
ms.custom: lyrana
---

# Monitoring Time Series Insights

When you have critical applications and business processes relying on Azure resources, you want to monitor those resources for their availability, performance, and operation. This article describes the monitoring data generated by Time Series Insights and how you can use the features of Azure Monitor to analyze and alert on this data.

## Monitor overview

The **Overview** page in the Azure portal for Time Series Insights includes charts that provide some usage metrics, such as the number of messages used and the number of devices connected to Time Series Insights.

## What is Azure Monitor

Time Series Insights creates monitoring data using [Azure Monitor](https://docs.microsoft.com/azure/azure-monitor/overview), which is a full stack monitoring service in Azure that provides a complete set of features to monitor your Azure resources in addition to resources in other clouds and on-premises.

Start with the article [Monitoring Azure resources with Azure Monitor](https://docs.microsoft.com/azure/azure-monitor/insights/monitor-azure-resource), which describes the following concepts:

- What is Azure Monitor?
- Costs associated with monitoring
- Monitoring data collected in Azure
- Configuring data collection
- Standard tools in Azure for analyzing and alerting on monitoring data

The following sections build on this article by describing the specific data gathered for Time Series Insights and providing examples for configuring data collection and analyzing this data with Azure tools.

## Collection and routing

Platform metrics are collected and stored automatically, but can be routed to other locations by using a diagnostic setting.

Resource Logs are not collected and stored until you create a diagnostic setting and route them to one or more locations.
See [Create diagnostic setting to collect platform logs and metrics in Azure](../azure-monitor/platform/diagnostic-settings.md) for the detailed process for creating a diagnostic setting using the Azure portal, CLI, or PowerShell. When you create a diagnostic setting, you specify which categories of logs to collect. The categories for Azure Time Series Insights are listed in link goes here...

> [!IMPORTANT]
> Enabling these settings requires additional Azure services (storage account, event hub, or Log Analytics), which may increase your cost. To calculate an estimated cost, visit the [Azure pricing calculator](https://azure.microsoft.com/pricing/calculator).

You can configure the following logs for Azure Time Series Insights:

   | Category | Description |
   |---|---|
   | Ingress  | The Ingress category tracks errors that occur in the ingress pipeline. This category includes errors that occur when receiving events (such as failures to connect to an Event Source) and processing events (such as errors when parsing an event payload). |

The metrics and logs you can collect are discussed in the following sections.

## Analyzing metrics

You can analyze metrics for Time Series Insights, along with metrics from other Azure services, by opening Metrics from the Azure Monitor menu. See [Getting started with Azure Metrics Explorer](https://docs.microsoft.com/azure/azure-monitor/platform/metrics-getting-started) for details on using this tool.

For a list of the metrics collected, see Monitoring Azure Time Series Insights data reference metrics.

This example shows the count of bytes received from all event sources in your Time Series Insights environment.

**Ingress received bytes** [![Azure Time Series ingress received bytes](media/how-to-monitor-tsi/ingress-received-bytes.png)](media/how-to-monitor-tsi/ingress-received-bytes.png#lightbox)

The example shows the count of bytes stored for the total size of events successfully processed and available for query in your Time Series Insights environment.

**Ingress stored bytes** [![Azure Time Series ingress stored bytes](media/how-to-monitor-tsi/ingress-stored-bytes.png)](media/how-to-monitor-tsi/ingress-stored-bytes.png#lightbox)

PLACEHOLDER FOR NAMESPACE

### Ingress

   |Metric  |Unit |Aggregation Type |Description |
   |---------|---------|---------|---------|
   |**Ingress Received Bytes** |  |  |Count of raw bytes read from event sources. Raw count usually includes the property name and value.|
   |**Ingress Received Invalid Messages** |  |  |Count of messages read from all Event Hubs or IoT Hubs event sources. |
   |**Ingress Received Messages** |  |  |Count of invalid messages read from all Azure Event Hubs or Azure IoT Hub event sources. |
   |**Ingress Stored Bytes** |  |  |Total size of events stored and available for query. Size is computed only on the property value. |
   |**Ingress Stored Events** |  |  |Count of flattened events stored and available for query. |
   |**Ingress Received Message Time Lag** |  |  |Difference in seconds between the time that the message is enqueued in the event source and the time it is processed in Ingress. |
   |**Ingress Received Message Count Lag** |  |  |Difference between the sequence number of last enqueued message in the event source partition and sequence number of message being processed in Ingress. |

### Storage

   |Metric Display Name |Unit |Aggregation Type |Description |
   |---------|---------|---------|---------|
   |**Failed twin reads from back end** |Count |Total |The count of all failed back-end-initiated twin reads. |
   |**Failed twin updates from back end** |Count |Total |The count of all failed back-end-initiated twin updates. |
   |**Response size of twin reads from back end** |Bytes |Average |The count of all successful back-end-initiated twin reads. |
   |**Size of twin updates from back end** |Bytes |Average |The total size of all successful back-end-initiated twin updates. |
   |**Successful twin reads from back end** |Count |Total| The count of all successful back-end-initiated twin reads. |
   |**Successful twin updates from back end** |Count |Total |The count of all successful back-end-initiated twin updates. |

## Analyzing logs

Data in Azure Monitor Logs is stored in tables where each table has its own set of unique properties. The data in these tables are associated with a Log Analytics workspace and can be queried in Log Analytics. To learn more about Azure Monitor Logs, see [Azure Monitor Logs overview](https://docs.microsoft.com/azure/azure-monitor/platform/data-platform-logs) in the Azure Monitor documentation.

To route data to Azure Monitor Logs, you must create a diagnostic setting to send resource logs or platform metrics to a Log Analytics workspace. To learn more, see [Collection and routing](https://docs.microsoft.com/azure/iot-hub/monitor-iot-hub#collection-and-routing).

## Sample Queries

TBD

## Alerts

Azure Monitor alerts proactively notify you when important conditions are found in your monitoring data. They allow you to identify and address issues in your system before your customers notice them. You can set alerts on [metrics](https://docs.microsoft.com/azure/azure-monitor/platform/alerts-metric-overview), [logs](https://docs.microsoft.com/azure/azure-monitor/platform/alerts-unified-log), and the [activity log](https://docs.microsoft.com/azure/azure-monitor/platform/activity-log-alerts). Different types of alerts have benefits and drawbacks.

When creating an alert rule based on platform metrics, be aware that for Time Series Insights platform metrics that are collected in units of count, some aggregations may not be available or usable. To learn more, see Supported aggregations in the Monitoring Azure IoT Hub data reference.

## Next Steps

- TBD
- TBD
- TBD
