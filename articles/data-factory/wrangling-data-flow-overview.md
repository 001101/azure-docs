---
title: Wrangling data flows in Azure Data Factory | Microsoft Docs
description: An overview of wrangling data flows in Azure Data Factory
author: djpmsft
ms.author: daperlov
ms.reviewer: gamal
ms.service: data-factory
ms.topic: conceptual
ms.date: 11/01/2019
---

# What are wrangling data flows?

Organizations need to do data preparation and wrangling for accurate analysis of complex data that continues to grow every day. Data preparation is also required so that organizations can use the data effectively in various business processes and reduce the time to value.

Wrangling data flows in Azure Data Factory allow you to do code-free data preparation at cloud scale iteratively. Wrangling data flows integrate with [Power Query Online](https://docs.microsoft.com/power-query/) and makes the best in class Power Query M functions available for data wrangling at cloud scale via spark execution.

Wrangling data flow translates M generated by the Power Query Online Mashup Editor into spark code for cloud scale execution and provides best in class monitoring experience.

Wrangling data flows are especially useful for data engineers or 'citizen data integrators'.

## Use cases

### Fast interactive data exploration and preparation

Multiple data engineers and citizen data integrators can interactively explore and prepare datasets at cloud scale. With the rise of volume, variety and velocity of data in data lakes, sometimes you need to explore and prepare a data set or are asked to create a new dataset. For example, you may need to create a dataset that 'has all customer demographic info for new customers since 2017'. You aren't mapping to a known target. You're exploring, wrangling, and prepping datasets to meet a requirement before publishing it in the lake. These are often used for less formal analytics scenarios. The prepped datasets can be used for doing transformations and machine learning operations downstream.

### Code-free agile data preparation

Citizen data integrators spend more than 60% of their time looking for and
preparing data. They're looking to do it in a code free manner to improve
operational productivity. Allowing citizen data integrators to enrich, shape, and
publish data using known tools like Power Query Online in a scalable manner drastically improves their
productivity. Wrangling data flow in Azure Data Factory enables the
familiar Power Query Online mashup editor to allow citizen data integrators to
fix errors quickly, standardize data, and produce high quality data to
support business decision makers.

### Data Validation

Visually scan your data in a code-free manner to remove any outliers, anomalies
and conform it to a shape for fast analytics.

## Frequently asked questions

### What are the supported regions for wrangling data flow?

Wrangling data flow is currently supported in data factories created in following regions:

* Australia East
* Canada Central
* Central India
* Central US
* East US
* East US 2
* Japan East
* North Europe
* Southeast Asia
* South Central US
* UK South
* West Central US
* West Europe
* West US
* West US 2

### What are the limitations and constraints with Wrangling data flow?

The following data stores are supported:

* DelimitedText dataset in Azure Blob Storage using account key authentication
* DelimitedText dataset in Azure Data Lake Storage gen2 using account key or service principal authentication
* DelimitedText dataset in Azure Data Lake Storage gen1 using service principal authentication
* Azure SQL Database and Data Warehouse using sql authentication. See below section for supported SQL types. There is no PolyBase or staging support for data warehouse.

At this time, Key Vault is not supported in linked services used in wrangling data flows. Dataset names can only contain alpha-numeric characters.

### What is the difference between mapping and wrangling Data Flow?

Mapping data flows provide a way to transform data at scale without any coding required. You can design a data transformation job in the data flow canvas by constructing a series of transformations. Start with any number of source transformations followed by data transformation steps. Complete your data flow with a sink to land your results in a destination. Mapping data flow is great at mapping via column map and transform from a known-unknown left side set of data sets to a known-unknown right side (e.g. pull a bunch of data and blend them to populate a dimensional model).

Wrangling Data Flow in ADF allows you to do agile data preparation/exploration. It enables the familiar Power Query Online mashup editor to do data preparation but now at scale via spark execution. With the rise of data lakes sometimes you just need to explore a data set or you are just asked to create a dataset in the lake that has all customer demographic info for new customers since 2017. In this case you are not mapping to a known target , you are just exploring data sets to meet the requirement and then you will publish it in the lake. These are often used for less formal/modelling analytics scenarios (i.e. data engineer built a data set for ad hoc analysis, data engineer is operationalizing a self-service project built by an information worker, etc.).

### What is the difference between Power Platform Dataflows and Wrangling Data Flow?

Power Platform Dataflows allow business users (citizen data analysts and app developers) to seamlessly import and transform data from a wide range of data sources into the Common Data Service and Azure Data Lake, in order to build PowerApps applications, Power BI reports or Flow automations. Power Platform Dataflows leverage the familiar Power Query data preparation experiences, which these users already know and feel comfortable with, from Power BI and Excel. Power Platform Dataflows also enable ease reuse within an organization and automatically handle orchestration (e.g. automatically refreshing dataflows that depend on another dataflow when the former one is refreshed).

Azure Data Factory (ADF) is a managed data integration service that allows Data Engineers/Citizen Data Integrator to create complex hybrid extract-transform-load (ETL), extract-load-transform (ELT), workflows. Wrangling Data Flow (WDF) in ADF empowers users with a code-free, serverless environment that simplifies data preparation in the cloud and scales to any data size, no infrastructure management required. It uses the industry leading Power Query data preparation technology (also used in Power Platform dataflows, Excel, Power BI) to seamlessly prepare/shape the data. Built to handle all the complexities and scale challenges of big data integration, Wrangling Data Flows allow users to quickly prepare data at scale via spark execution. Users can build resilient data pipelines in an accessible visual environment with our browser-based designer and let ADF handle the complexities of Spark execution. Build schedules for your pipelines and monitor your data flow executions from the ADF monitoring portal. Easily manage data availability SLAs with ADFâ€™s rich availability monitoring and alerts and leverage built-in CI/CD capabilities to save and manage your flows in a managed DataOps environment. And establish alerts and view execution plans to validate that your logic is performing as planned as you tune your data flows.

### Supported SQL Types

Wrangling data flow supports the following data types in SQL, for data types that is not in the list, you will get an validation error:
"short"
"double"
"real"
"float"
"char"
"nchar"
    "varchar"
"nvarchar"
"integer"
"int"
"bit"
"boolean"
"smallint"
"tinyint"
"bigint"
"long"
"text"
"date"
"datetime"
"datetime2"
"smalldatetime"
"timestamp"
"uniqueidentifier"
"xml"

   ** Other data types will be supported shortly.

## Next steps
